---
title: "Basics of MCMC sampling in Bayesian analysis"
author: "Stephen Rhodes - srhodes@research.baycrest.org"
date: 'Last updated: `r Sys.Date()`'
output:
  ioslides_presentation:
    widescreen: yes
  beamer_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
```

# MCMC sampling

## Why sample?

> - $p(\theta \mid y)$ is a *distribution* but the shape of that distribution is not always directly attainable.
> - For a normal prior on the mean and a normal likelihood function the posterior distribution for the mean is also a normal distribution. 
> - The normal is a *conjugate prior* for the normal likelihood. (The Beta distribution is conjugate for the binomial distribution).
> - For most models an analytic expression of the posterior distribution is not possible.
> - In these situations sampling is needed to approximate the posterior distribution. This is what is offered by software like JAGS, BUGS, Stan etc.

## Intro to MCMC

Markov Chain Monte Carlo

- *Markov Chain* - a "memoryless" chain of events. Each step depends on the current state (e.g. parameter value) and not previous ones
- *Monte Carlo* - Repeated random sampling

Goal of MCMC - to approximate a target distribution

## The Metropolis Algorithm

- We want to approximate $p(\theta \mid y)$ which is proportional to the prior times the likelihood. 
- The Metropolis algorithm allows us to explore the space of possible parameter values. Values are "visited" in proportion to their density under the posterior.

## The Metropolis Algorithm

> 1. Select a stating point in the parameter space. This is $\theta_{\text{current}}$
> 2. A move in parameter space is suggested from a *proposal distribution*. This is $\theta_{\text{new}} = \theta_{\text{current}} + \Delta\theta$
> 3. The probability that we accept the proposed move is: $p_{\text{accept}} = \min\left(\frac{f(\theta_{\text{new}})}{f(\theta_{\text{current}})}, 1\right)$
> 4. Sample a uniform number between 0 and 1. If this number is smaller than $p_{\text{accept}}$ then we accept the proposal and $\theta_{\text{new}}$ becomes $\theta_{\text{current}}$ for the next step. If not we stick with the $\theta_{\text{current}}$ we had originally.
> 5. Repeat steps 2-4 many times and record $\theta_{\text{current}}$ at the beginning of each loop.

Note for our Bayesian purposes $f(x) = p(x)p(y \mid x)$.

## The Metropolis Algorithm

Why does it work?

> - If the proposed parameter value is "better" then the current value (i.e. produces a higher posterior density) then it is *always* visited.
> - If it is not better than the current value it is visited in proportion to how it compares to the current value: $f(\theta_{\text{new}})/f(\theta_{\text{current}})$
> - Thus, values with a higher posterior density are visited more often. Running a long chain and assessing how often certain parameter values are represented gives us the posterior even if we don't know how to express its form analytically.

## Metropolis Example

```{r, echo=FALSE, fig.show='hide'}

# load the functions
source("metropolis-example.R")

library(coda)

```

- Suppose we want to estimate the mean ($\mu$) IQ (or some other cognitive) score of a group of participants (N = `r N`).
- The test is scaled to have a population standard deviation of 15 so we assume that this is known.

```{r, echo=FALSE, fig.height=4}

hist(Y, xlab = "Score", main = "Test Scores", col = "seagreen3")

```

## Metropolis Example

- We need to choose a prior distribution for $\mu$
- Here we use a normal distribution with a mean of `r prior_m` and standard deviation of `r prior_sd`

```{r, echo=FALSE}

curve(dnorm(x = x, prior_m, prior_sd), from = prior_m-prior_sd*3, to = prior_m+prior_sd*3, xlab = bquote(mu), ylab="", main = "Prior", col = "darkgreen", lwd = 2)

```

## Metropolis Example

- The script `metropolis-example.R` contains code implementing a Metropolis algorithm
- Have a look to see what is involved...

```{r, echo=FALSE}

# plot the steps in the chain
plot(samples, xlab = "Step", ylab = bquote(mu), type="l", col="blue")

```

## Let's take a look at some steps

<div class="columns-2">

```{r, echo=FALSE, fig.width=5}

step = 500:504

mu = c(105, 111, 111, 109, 113)

plot(step, mu, xlab = "Step", ylab = bquote(mu), type="l", col="blue")
points(step[1], mu[1], pch=16, cex=2, col="red")

```

</br>

**Step 500**

- The current value of $\mu$ is `r mu[1]`. A new value is proposed from a normal distribution with a mean of `r mu[1]` and a standard deviation of 5. The proposed value is 111.
- Next we calculate $p(\mu)p(y \mid \mu)$ for both the current and proposed values of $\mu$ (we use the `dnorm` function twice as both the prior and the likelihood are normal).
- In this case $p_{\text{accept}} = 1$ so we accept the proposal for step 501

</div>

## Let's take a look at some steps

<div class="columns-2">

```{r, echo=FALSE, fig.width=5}

plot(step, mu, xlab = "Step", ylab = bquote(mu), type="l", col="blue")
points(step[2], mu[2], pch=16, cex=2, col="red")

```

</br>

**Step 501**

- The current value of $\mu$ is `r mu[2]`. The proposed value is 103.
- The ratio of $p(\mu)p(y \mid \mu)$ for proposed relative to current value of $\mu$ gives $p_{\text{accept}} = .4$
- The number sampled via `runif(n = 1, min = 0, max = 1)` is 0.6 so the proposal is *rejected*
- We stick with 111 for the next step

</div>

## Let's take a look at some steps

<div class="columns-2">

```{r, echo=FALSE, fig.width=5}

plot(step, mu, xlab = "Step", ylab = bquote(mu), type="l", col="blue")
points(step[3], mu[3], pch=16, cex=2, col="red")

```

</br>

**Step 502**

- The current value of $\mu$ is `r mu[3]`. The proposed value is `r mu[4]`.
- The ratio of $p(\mu)p(y \mid \mu)$ for proposed relative to current value of $\mu$ gives $p_{\text{accept}} = .8$
- The number sampled via `runif(n = 1, min = 0, max = 1)` is 0.34 so the proposal is *accepted*
- The current value is set to `r mu[4]` for step 503.

and so on...

</div>

## It works! 

For a normal likelihood with a normal prior on the mean the form of the posterior distribution is known. So we can compare the results. 

```{r, echo=FALSE}

# plot the histogram
hist(samples, xlab = bquote(mu), main = paste0("N samples = ", length(samples)), col = "grey", breaks = 30, probability = T)

# calculate the exact form of the posterior to compare to the samples
#post = posterior_quantities(y = Y, prior_mean = prior_m, prior_sd = prior_sd)
curve(dnorm(x, mean = post[1], sd = post[2]), from = min(samples), to = max(samples), col = "red", lwd = 2, add = T)

```

## It works! 

Increasing the number of steps improves the approximation.

```{r, echo=FALSE}

samples2 = metropolis_iq(y = Y, 
                        prior_mean = prior_m,
                        prior_sd = prior_sd, 
                        proposal_sd = 5,
                        n_samples = 10000, 
                        start = 100)

# plot the histogram
hist(samples2, xlab = bquote(mu), main = paste0("N samples = ", length(samples2)), col = "grey", breaks = 30, probability = T)

# calculate the exact form of the posterior to compare to the samples
#post = posterior_quantities(y = Y, prior_mean = prior_m, prior_sd = prior_sd)
curve(dnorm(x, mean = post[1], sd = post[2]), from = min(samples2), to = max(samples2), col = "red", lwd = 2, add = T)

```


# Gibbs Sampling

<!--
## Reminder of the Metropolis algorithm

1. Select a stating point in the parameter space.
2. A move in parameter space is suggested from a *proposal distribution*.
3. We work out the probability of accepting the move via $p_{\text{accept}} = \min\left(\frac{f(\theta_{\text{new}})}{f(\theta_{\text{current}})}, 1\right)$.
4. If a uniform(0, 1) number is smaller than $p_{\text{accept}}$ then we accept the new parameter value for the next cycle.
5. Repeat steps 2-4 many times.
-->

## Gibbs Sampling

More complicated than our Metropolis algorithm but better for large numbers of parameters, which easily occurs in hierarchical modeling. Imagine a two parameter situation $\{\theta_1, \theta_2\}$ with independent prior distributions $p(\theta_1, \theta_2) = p(\theta_1)p(\theta_2)$.

> 1. Start at a random point in the (two dimensional) parameter space.
> 2. Select one of the parameters (e.g. $\theta_1$). Sample a new value for it from $p(\theta_1 \mid \theta_2, y)$ using the current value of the other parameters (in this case, $\theta_2$).
> 3. The sampled value comes directly from the posterior of $\theta_1$ conditional on the current value of $\theta_2$ so the move is *always* accepted.
> 4. Go back to step 2 and repeat many times.

To do this we need to know the conditional distributions for each parameter given each of the others $p(\theta_i \mid \theta_{i \neq j}, y)$. Luckily software (Stan) can do this for us!

## Sampling in Stan

- Stan uses an even more complex algorithm, called [Hamiltonian Monte Carlo](https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo) (specifically, a No-U Turn Sampler, NUTS)
- This is more effective for high dimensional problems
- The main difference is in how proposals for the next step are generated
- See [Betancourt (2017)](https://arxiv.org/pdf/1701.02434.pdf) for a conceptual introduction

