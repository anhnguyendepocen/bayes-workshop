---
title: "Introduction to `Stan`"
author: "Stephen Rhodes - srhodes@research.baycrest.org"
date: 'Last updated: `r Sys.Date()`'
output:
  ioslides_presentation:
    widescreen: yes
    logo: images/stan.png
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F)

library(brms)
library(rstan)
library(loo)
library(bridgesampling)
library(bayesplot)

load("../examples/brms-example1.RData")
load("../examples/stan-example1.RData")
```

## Overview

- Anatomy of a Stan model
- Stan analysis of the `sleepstudy` dataset (stan-example1.R)
- The `rstan` package
- A more complex example that (I think) cannot be estimated with `brms` (stan-example2.R)

# Anatomy of a Stan model

## Anatomy of a Stan model

Necessary blocks (more info [here](https://mc-stan.org/docs/2_18/reference-manual/blocks-chapter.html))

```r
data {
  \\ what we are modeling
}
parameters {
  \\ the variables being sampled by Stan
}
model {
  \\ priors and likelihood function
}
```

## Anatomy of a Stan model

Optional blocks (more info [here](https://mc-stan.org/docs/2_18/reference-manual/blocks-chapter.html))

```r
functions {
  \\ user defined functions
}
transformed data {
  \\ as the name suggests
}
transformed parameters {
  \\ sometimes useful to speed up program
}
generated quantities {
  \\ does things with the samples 
  \\ e.g., calculate log likelihood, posterior predictions
}
```

## `brms::stancode`

- You can see the code that `brms` produces
- Probably of limited use until familiar with the intricacies of `Stan`...

```{r}
stancode(m1)
```

# stan-example1.R

## `sleepstudy` Example

```{r}
sleepstudy <- read.csv("../examples/sleepstudy.csv")
head(sleepstudy)
```

## `data`

```r
data {
  int<lower=0> N;             // n observations
  vector[N] y;                // reaction times
  matrix[N,2] x;              // design matrix (intercept, days)
  int<lower=0> S;             // n subjects
  int<lower=1,upper=S> id[N]; // subject ids
}
```
More on [data types](https://mc-stan.org/docs/2_18/reference-manual/data-types-chapter.html)

## `parameters`

Below are the parameters for the simple (non-hierarchical) regression model (model 1)

```r
parameters {
  vector[2] beta;             // fixed effects
  real<lower=0> sigma;        // residual SD
}
```

## `model`

```r
model {
  // priors
  sigma ~ cauchy(0,50);
  beta[1] ~ normal(300,100);
  beta[2] ~ normal(0,50);
  // likelihood
  y ~ normal(x * beta, sigma);
}
```

- `~` sampling statement (is distributed as)
- `=` assignment

## `generated quantities`

```r
generated quantities {
  vector[N] log_lik;      // log likelihood matrix
  vector[N] y_rep;        // posterior predictions
  for (i in 1:N){
    log_lik[i] = normal_lpdf(y[i] | x[i] * beta, sigma);
    y_rep[i] = normal_rng(x[i] * beta, sigma);
  }
}
```

- `log_lik`: log likelihood matrix. Used for calculating loo, waic
- `y_rep`: samples from the posterior predictive distribution

## `.stan`

- These blocks are all bundled into a `.stan` file
- See "examples/stan-models/example1-m1.stan" for this example program
- We can use the `rstan` package to get samples

# The `rstan` package

## `rstan`

Is the interface between `R` and `Stan`

Steps:

1. Put data into a list
2. Call the `stan()` function 
3. Do stuff with the samples

## Data list with `sleepstudy`

Everything in the `data` block should appear here

```r
data_list = list(
  N = nrow(sleepstudy),
  y = sleepstudy$Reaction,
  x = model.matrix(~ Days, data = sleepstudy),
  S = length(unique(sleepstudy$Subject)),
  id = as.numeric(sleepstudy$Subject) # ids should go from 1:S
)
```

```{r}
head(model.matrix(~ Days, data = sleepstudy))
```

## Run samples with `stan()`

```r
m1_fit <- stan(
  file = "examples/stan-models/example1-m1.stan",
  data = data_list,
  chains = 4,
  warmup = 1000,
  iter = 2000,
  cores = 4
)
```

This runs 4 separate chains for 2000 samples (each) and discards the first 1000 (4000 post-warmup samples total)

## `stanfit` object

```{r}
summary(m1_fit, pars="beta")
```

## `stanfit` object

```{r}
plot(m1_fit, pars="beta")
```

## `stanfit` object

```{r}
traceplot(m1_fit, pars="beta")
```

## Posterior predictive check

```{r}
yrep <- extract(m1_fit, pars = "y_rep")[[1]]
ppc_stat(sleepstudy$Reaction, yrep, stat = "mean")
```

## Posterior predictive check

```{r}
# like pp_check()
ppc_dens_overlay(sleepstudy$Reaction, yrep[sample(nrow(yrep), size = 100),])
```

## `loo`

Using the [`loo` package](https://cran.r-project.org/web/packages/loo/index.html)

```r
log_lik_1 = extract_log_lik(m1_fit, merge_chains = F)
r_eff_1 = relative_eff(exp(log_lik_1))
loo_1 = loo(log_lik_1, r_eff = r_eff_1)
```

```{r}
loo_1
```

## Marginal likelihood (for Bayes factors)

Using the [`bridgesampling` package](https://cran.r-project.org/web/packages/bridgesampling/index.html)

```r
ml_1 = bridge_sampler(m1_fit)
```
```{r}
ml_1
```

# stan-example2.R | fairly complex model

## 2D recall data {.columns-2}

```{r echo=F}

recall_2d = read.csv("../examples/recall-2D.csv")

```

```{r, echo=F}
par(pty='s', mar=c(1,1,1,1))
plot(NA, xlim=c(-15,15), ylim=c(-15,15), xlab="", ylab="", axes=F)

for (i in 1:100){
  with(recall_2d[i,], lines(c(px, rx), c(py, ry), lty=2, col="lightgrey"))
  with(recall_2d[i,], points(c(px, rx), c(py, ry), type='p', col=c("black", "red")))
}
legend("bottomleft", legend = c("Studied", "Recalled"), col = c("black", "red"), pch=1, bty='n')
par(pty='m', mar=c(5, 4, 4, 2) + 0.1)
```

- Data from a hypothetical study where participants study the location of an item
- Then recall the location later on

## 2D recall data

`px` & `py` = presented x,y coordinates; `rx` & `ry` = recalled coordinates

```{r}
head(recall_2d)
```

## 2D recall data

```{r, echo=F}
recall_2d$error = with(recall_2d, sqrt((px-rx)^2 + (py-ry)^2))

with(recall_2d, hist(error, breaks=30, col="lightgreen", border=F, xlab="Distance between studied and recalled", main="Recall Error", probability = T))

with(recall_2d, lines(density(error , from=0)))

```

## Mixture model

```
Distribution of recalled locations = mixture of responses from memory and guesses
```

$$
\mathbf{r}_{ij} \sim m_i \times \phi(\mathbf{p}_j, s_i) + (1 - m_i) \times \frac{1}{A}
$$

- $i$ = Individuals; $j$ = trials 
- $\mathbf{r}$ = recalled location, $\mathbf{p}$ = presented (studied) location. 
- $m_i$ = probability of a response from memory for individual $i$
- $s_i$ = imprecision of memory for individual $i$
- $A$ = area where responses are allowed

## Mixture model

$$
\mathbf{r}_{ij} \sim m_i \times \phi(\mathbf{p}_j, s_i) + (1 - m_i) \times \frac{1}{A}
$$

$$
\mbox{logit}(m_i) \sim \mbox{Normal}(\mu_m, \sigma_m) \\
\mbox{log}(s_i) \sim \mbox{Normal}(\mu_s, \sigma_s)
$$

We need priors for the population level parameters, $\mu_m$, $\mu_s$, $\sigma_m$, and $\sigma_s$

## example2.stan

```r
data {
  int<lower=0> N;             // N observations
  int<lower=0> S;             // number of participants
  int<lower=1,upper=S> id[N]; // participant id
  vector[N] p_x;              // presented x coordinate
  vector[N] p_y;              // presented y coordinate
  vector[N] r_x;              // recalled x coordinate
  vector[N] r_y;              // recalled y coordinate
  real<lower=0> A;            // for determining uniform (guess) density
}
```

## example2.stan

```r
parameters {
  real mu_m;                  // population mean for m (logit scale)
  real mu_s;                  // population mean for s (log scale)
  
  real<lower=0> sd_m;         // population sd for m (logit)
  real<lower=0> sd_s;         // population sd for s (log)
  
  vector[S] m;                // individual m parameters (logit)
  vector[S] s;                // individual s parameters (log)
}
```

$$
\mbox{logit}(m_i) \sim \mbox{Normal}(\mu_m, \sigma_m) \\
\mbox{log}(s_i) \sim \mbox{Normal}(\mu_s, \sigma_s)
$$

## example2.stan

```r
model {
  // priors
  sd_m ~ cauchy(0,2.5);
  sd_s ~ cauchy(0,2.5);
  mu_m ~ normal(0,5);
  mu_s ~ normal(0,5);
  
  // sample individual parameters from population
  for (i in 1:S){
    m[i] ~ normal(mu_m, sd_m);
    s[i] ~ normal(mu_s, sd_s);
  }
... // continued on next slide
```

$$
\mbox{logit}(m_i) \sim \mbox{Normal}(\mu_m, \sigma_m) \\
\mbox{log}(s_i) \sim \mbox{Normal}(\mu_s, \sigma_s)
$$

## example2.stan

```r
  // likelihood
  for (n in 1:N)
    target += log_mix(inv_logit(m[id[n]]),
                      normal_lpdf(r_x[n] | p_x[n], exp(s[id[n]])) + 
                      normal_lpdf(r_y[n] | p_y[n], exp(s[id[n]])),
                      log(1/A));
}
```

Not quite the same, but equivalent to...

$$
\mathbf{r}_{ij} \sim m_i \times \phi(\mathbf{p}_j, s_i) + (1 - m_i) \times \frac{1}{A}
$$

## stan-example2.R

Run through script...
