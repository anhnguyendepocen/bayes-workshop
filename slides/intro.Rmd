---
title: "Introduction to Bayesian Analysis"
author: "Stephen Rhodes - srhodes@research.baycrest.org"
date: 'Last updated: `r Sys.Date()`'
output:
  ioslides_presentation:
    widescreen: yes
  beamer_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F)

library(brms)
library(bayesplot)

load("../examples/brms-example1.RData")
```

## Overview

- Why go Bayesian?
- Introduction to Bayesian analysis
    - What's the purpose of Bayesian estimation?
    - MCMC sampling
    - How good are my samples?
    - Posterior predictive checks
    - Model comparison
    - Summarizing the posterior
    
# Why go Bayesian?

## Why go Bayesian?

> - It tells you what you want to know. Given the data,
>     - What interval contains an unobserved parameter with .95 (or some other) probability?
>     - What's the relative weight of evidence for one model (e.g., 'null') vs. another (e.g., an alternative).
> - We almost always have some prior knowledge of reasonable parameter values - this should be incorporated
> - Results are not dependent on a 'sampling plan' (see, e.g., Kruschke & Liddell, 2018 for more)
    
# Introduction to Bayesian analysis

## Purpose

> - To re-allocate credibility over parameters values based on the observed data (Kruschke, 2015)
> - Given the observed data, what parameter values should we most strongly believe in?
> - To obtain this we need to start with a model and some *prior* expectation as to the probability of certain parameter values in this model (more on this later)

## Bayesian estimation

- $\theta$ = parameter(s), $y$ = observed data
- $p(y \mid \theta)$ = the likelihood
- $p(\theta)$ = the prior
- $p(y)$ = probability of the data ("the evidence")
<!-- 
- The model: $p(\theta, y) = p(\theta)p(y \mid \theta)$ (see Gelman et al., 2013)
- To allocate credibility to the parameter values we can "condition" on the observed data. This gives us the *posterior* distribution of the parameters given the data:
-->

$$
p(\theta \mid y) = \frac{p(\theta)p(y \mid \theta)}{p(y)}
$$

## Bayesian estimation

$p(y)$ does not depend on the model parameters so we can omit it in favor of the *unnormalized posterior*

$$
p(\theta \mid y) \propto p(\theta)p(y \mid \theta)
$$

**The posterior is proportional to the prior times the likelihood**

<!--
## Bayesian estimation

```{r}

cols = viridis::viridis(3)

x = seq(-5, 5, by = .2)

pr = dnorm(x, mean = 0, sd = 3)
l = dnorm(x, mean = 0, sd = 1)
po = pr*l

plot(NA, xlim = c(-5,5), ylim = c(0, max(c(pr, l, po))))
lines(x, pr, type='b', col=cols[1])
lines(x, l, type='b', col=cols[2])
lines(x, po, type='b', col=cols[3])

```
-->

## Conceptual example

Linear regression:

$$
y_i = \beta_0 + \beta_1x_i + \epsilon_i
$$

$$
\epsilon_i \sim \mbox{Normal}(0, \sigma)
$$

Or

$$
y_i \sim \mbox{Normal}(\beta_0 + \beta_1x_i, \sigma)
$$

## Conceptual example

We need a prior, $p(\beta_0, \beta_1, \sigma)$

If $x$ and $y$ have been scaled ($z$-scored), a reasonable choice would be:

- $\beta_0 \sim \mbox{Normal}(0, 3)$
- $\beta_1 \sim \mbox{Normal}(0, 3)$
- $\sigma \sim \mbox{Cauchy}(0, 2.5)^{+}$

## Conceptual example

These priors essentially say that we expect either a positive or negative relationship between $x$ and $y$. 

If we had strong reason to expect that $y$ should increase with $x$ we could instead use:

- $\beta_1 \sim \mbox{Normal}(0, 3)^{+}$

# MCMC Sampling

## Why sample?

> - The posterior, $p(\theta \mid y)$, is a *distribution* but the shape of that distribution is not always directly attainable (i.e., no analytic expression).
> - In these situations sampling is needed to approximate the posterior distribution. This is what is offered by software like JAGS, BUGS, Stan etc.

## MCMC

Markov Chain Monte Carlo

- *Markov Chain* - a "memoryless" chain of events. Each step depends on the current state (e.g. parameter value) and not previous ones
- *Monte Carlo* - Repeated random sampling

Goal of MCMC - to approximate a target distribution

## MCMC

- The slides [mcmc](mcmc.html) introduce the basics of MCMC in Baysian analyses via a simple Metropolis Hastings algorithm (see metropolis.example.R)
- The important points are:
    - MCMC generates a chain of samples
    - Once the chain has *converged* on a stable distribution, parameter values are visited in proportion to their posterior probability/ density

# How accurate is the MCMC chain?

## Things to consider

```{r, echo=FALSE, fig.show='hide'}

# load the functions
source("metropolis-example.R")

library(coda)

```

- Burn in (or warm up)
- Autocorrelation
- Effective Sample Size (ESS)
- Convergence and the Potential Scale Reduction Factor (PSRF)
- Thinning

## Burn in (or warm up)

```{r, echo=FALSE}

samples3 = metropolis_iq(y = Y, prior_mean = prior_m, prior_sd = prior_sd, proposal_sd = 1, n_samples = 1000, start = 0)

plot(samples3, xlab = "Step", ylab = bquote(mu), type="l", col="blue")

```

## Autocorrelation

```{r, echo=FALSE}

samples4 = metropolis_iq(y = Y, prior_mean = prior_m, prior_sd = prior_sd, proposal_sd = .1, n_samples = 1000, start = 110)

plot(samples4, xlab = "Step", ylab = bquote(mu), type="l", col="blue")

```

## Autocorrelation

```{r, echo=FALSE}

par(mfrow=c(1,2))
autocorr.plot(as.mcmc(samples4), auto.layout = F)
autocorr.plot(as.mcmc(samples), auto.layout = F)

```

## Effective Sample Size

A way of estimating the number of independent samples once accounting for autocorrelation:

$$
ESS = \frac{N}{1 + 2\sum_{k = 1}^{\infty} \rho_k}
$$

Where $\rho_k$ is the autocorrelation at lag $k$. Think of this as dividing the number of samples by the amount of autocorrelation. In practice the sum stops when the autocorrelation is small (e.g. $\rho_k < 0.05$; see Kruschke, 2015, p. 184).

## Convergence

How do we know that we have converged onto a stable distribution?

```{r, echo=FALSE}

samples5 = metropolis_iq(y = Y, prior_mean = prior_m, prior_sd = prior_sd, proposal_sd = 5, n_samples = 1000, start = 100)

samples6 = metropolis_iq(y = Y, prior_mean = prior_m, prior_sd = prior_sd, proposal_sd = 5, n_samples = 1000, start = 120)

plot(samples5, xlab = "Step", ylab = bquote(mu), type="l", col="blue", ylim=c(100, 120))
lines(samples6, col = "orchid")
abline(v = 100, col="red", lty=2)

```

## Convergence

> - Run multiple sequences (*chains*) with different starting points
> - Compare variation between different chains to variation within chains. When these are approximately equal we can claim to have converged on the target distribution.
> - This is measured via $\hat{R}$ and conventionally a value $< 1.1$ is considered converged.
> - $\hat{R}$ is also referred to as the Gelman-Rubin convergence diagnostic or the Potential Scale Reduction Factor (PSRF).

## Convergence

```{r, echo=FALSE, fig.width=10}

par(mfrow=c(1,2))
# converged
plot(samples5, xlab = "Step", ylab = bquote(mu), type="l", col="blue", ylim=c(100, 120))
lines(samples6, col = "orchid")

R_hat = round(gelman.diag(mcmc.list(as.mcmc(samples5), as.mcmc(samples6)))$psrf[1,1], 2)

text(x = 600, y = 118, labels = bquote(hat(R) %~~% .(R_hat)))

# not converged
samples7 = metropolis_iq(y = Y - 5, prior_mean = prior_m, prior_sd = prior_sd, proposal_sd = 5, n_samples = 1000, start = 118)

plot(samples5, xlab = "Step", ylab = bquote(mu), type="l", col="blue", ylim=c(100, 120))
lines(samples7, col = "orchid")

R_hat = round(gelman.diag(mcmc.list(as.mcmc(samples5), as.mcmc(samples7)))$psrf[1,1], 2)

text(x = 600, y = 118, labels = bquote(hat(R) %~~% .(R_hat)))

```

## Thinning

```{r, echo=FALSE, fig.width=10}

par(mfrow=c(1,2))

samples8 = metropolis_iq(y = Y, prior_mean = prior_m, prior_sd = prior_sd, proposal_sd = .5, n_samples = 10000, start = 110)

plot(samples8, xlab = "Step", ylab = bquote(mu), main = "Full Chain", type="l", col="blue")

plot(samples8[seq(1, 10000, 10)], xlab = "Step", ylab = bquote(mu), main = "Keep every 10th sample", type="l", col="blue")

```

## Thinning

```{r, echo=FALSE, fig.width=10}

par(mfrow=c(1,2))

autocorr.plot(as.mcmc(samples8), auto.layout = F, main = "Full Chain")
autocorr.plot(as.mcmc(samples8[seq(1, 10000, 100)]), auto.layout = F, main = "Keep every 10th sample")

```

## Thinning

- If autocorrelation is really bad thinning might help, but it might suggest deeper problems with your model (see Gelman et al., 2014)
- It has been claimed that thinning is "often unnecessary and always inefficient" ([Link & Eaton, 2012](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/j.2041-210X.2011.00131.x)). 
- Often it is better to keep the full chains.

# Posterior Predictive Checking

## Posterior Predictive Checking

- PPCs are a way of evaluating the performance of a particular model and identifying potential areas/ sources of misfit
- Involves simulating outcomes ($y_{\mbox{rep}}$) from the model
- Incorporating uncertainty in the estimated parameters

## Posterior Predictive Checking

For each step in the chain (or a random subset of the chain), simulate $N$ observations from the model with parameters set to the current step in the chain (where $N$ is the size of the original data set)

We can compare these simulated outcomes to the observed data

## Posterior Predictive Checking

```{r, echo=F}
pp_check(m1, nsamples=100)
```

## Posterior Predictive Checking

- We can also caculate specific quantities (e.g., max, min, mean) for each posterior predictive sample and compare to those from the observed data set
- If a particular statistic ($T$) from the observed data is rare under the model predictions, this is indicative of misfit

## Posterior Predictive Checking

```{r, echo=F}
ppc_stat(sleepstudy$Reaction , posterior_predict(m1), stat = "min")
```

## Posterior Predictive Checking

```{r, echo=F}
ppc_stat_grouped(sleepstudy$Reaction , posterior_predict(m1), group=sleepstudy$Subject, stat = "mean")
```

# Model comparison

## Model comparison

- Out-of-sample prediction accuracy
    - Approximate leave-one-out cross validation (LOO)
    - Widely Applicable Information Criterion (WAIC)
- Marginal likelihood
    - Bayes factor
    - Posterior model probability

## LOO and WAIC

Both try to estimate the *expected log predictive density* (elpd) for a new data set

- LOO can be approximated by [importance sampling](https://en.wikipedia.org/wiki/Importance_sampling), specifically we will use parieto smoothed importance sampling (psis) as implemented in the `loo` package
- WAIC is a Bayesian extension of AIC ([Watanabe, 2010](http://www.jmlr.org/papers/volume11/watanabe10a/watanabe10a.pdf)). It essentially estimates the effective number of parameters of the model and uses this to penalize its predictive accuracy

Larger elpd is better but note that LOO and WAIC are often reported on deviance scale (multiplied by -2), in which case smaller values indicate better fit

## LOO and WAIC

- Asymtotically, WAIC and LOO should the the same, although LOO is advocated for more strongly where possible (see [Vehtari et al., 2017](https://arxiv.org/pdf/1507.04544.pdf))
- When not possible (as we'll see in some `brms` examples), $K$-fold cross validation can be used

## Bayes factors

$$
\frac{p(M_1 \mid y)}{p(M_2 \mid y)} = \frac{p(y \mid M_1)}{p(y \mid M_2)} \times \frac{p(M_1)}{p(M_2)}
$$

$$
\frac{p(M_1 \mid y)}{p(M_2 \mid y)} = B_{1,2} \times \frac{p(M_1)}{p(M_2)}
$$

- The Bayes factor, $B$, is the 'updating factor'
- How much does our belief in model 1 over model 2 change, having seen the data

## Marginal Likelihood

$$
p(y \mid M_i) = \int_{\theta_i} p(y \mid \theta_i, M_i) p(\theta_i, M_i) d\theta_i
$$

- `r emo::ji("scared")`
- We will use bridge sampling to estimate the marginal likelihood (see [Gronau et al., 2017](https://www.sciencedirect.com/science/article/pii/S0022249617300640) for an introduction)
- There are other approaches such as ['transdimensional MCMC'](https://www.sciencedirect.com/science/article/abs/pii/S0022249611000423) or the JZS 'default' Bayes factors implemented in the [`BayesFactor`](https://cran.r-project.org/web/packages/BayesFactor/BayesFactor.pdf) package (only normal models)

<!--Something on Lindley's paradox and importance of priors here?-->

# Summarizing the Posterior

## Summarizing the Posterior

- Each sample in the chain is a point in the joint parameter space
- For inference, we'll focus on the marginal distribution of each parameter of interest
- Usually we'll be interested in the mean, median, and quantiles of the posterior

## Credible interval and highest density interval

You'll see both of these around...

- **95% Credible Interval:** the 2.5% to 97.5% quantiles (output by default in brms)
- **95% Highest Density Interval:** an interval containing 95% of the posterior mass such that *values contained within the interval have higher posterior density than values outside the interval* (can use `HDInterval::hdi()` to calculate)

## Credible interval and highest density interval

```{r, echo=F}

sym = rnorm(10000)

h1=hist(sym, xlab="", ylab="", main="", breaks = 30, probability = T, col = "lightblue", border=F)

sym_hdi = HDInterval::hdi(sym)
sym_ci = quantile(sym, probs = c(.025, .975))

segments(x0 = sym_hdi[1], y0 = 0, x1 = sym_hdi[2], y1 = 0, lwd=3, col="red")
text(x=0, y=0, labels = sprintf("HDI: [%.2f, %.2f]", sym_hdi[1], sym_hdi[2]), col='red', adj=c(.5,-1))

segments(x0 = sym_ci[1], y0 = .25*max(h1$density), x1 = sym_ci[2], y1 = .25*max(h1$density), lwd=3)
text(x=0, y=.25*max(h1$density), labels = sprintf("CI: [%.2f, %.2f]", sym_ci[1], sym_ci[2]), adj=c(.5,-1))

```

## Credible interval and highest density interval

```{r, echo=F}

#asym = rgamma(10000, shape = 1, rate = .001)
asym = rlnorm(10000, meanlog = 1, sdlog = .5)


h1=hist(asym, xlab="", ylab="", main="", breaks = 30, probability = T, col = "lightblue", border=F)

asym_hdi = HDInterval::hdi(asym)
asym_ci = quantile(asym, probs = c(.025, .975))

segments(x0 = asym_hdi[1], y0 = 0, x1 = asym_hdi[2], y1 = 0, lwd=3, col="red")
text(x=mean(asym), y=0, labels = sprintf("HDI: [%.2f, %.2f]", asym_hdi[1], asym_hdi[2]), col='red', adj=c(.5,-1))

segments(x0 = asym_ci[1], y0 = .25*max(h1$density), x1 = asym_ci[2], y1 = .25*max(h1$density), lwd=3)
text(x=mean(asym), y=.25*max(h1$density), labels = sprintf("CI: [%.2f, %.2f]", asym_ci[1], asym_ci[2]), adj=c(.5,-1))

```

## The Savage-Dickey Bayes factor

- AKA the Savage-Dickey density ratio (see [Wagenmakers et al., 2010](https://www.sciencedirect.com/science/article/pii/S0010028509000826) for an introduction)
- For a point hypothesis regarding a parameter value, we compare the height of the posterior distribution to the height of the prior distribution *at that particular value*
- The relative height of the posterior and prior tells us how much our beleive *in that particular* value has changed after seeing the data

## The Savage-Dickey Bayes factor

```{r, echo=F}

plot_savdic <- function(prior_sd=1, post_mu=.8, post_sd=.5){
  cols = viridis::viridis(2, begin = .2, end = .8)
  
  x = seq(-3,3,.01)
  
  stopifnot(any(x==0))

  prior = dnorm(x, mean = 0, sd = prior_sd)
  posterior = dnorm(x, mean = post_mu, sd = post_sd)
  
  plot(NA, xlim=c(-3,3), ylim=c(0, max(c(prior, posterior))), xlab=bquote(theta), ylab='')
  
  lines(x, prior, col=cols[1], lwd=2)
  lines(x, posterior, col=cols[2], lwd=2)
  
  points(0, prior[x==0], col=cols[1], pch=16, cex=1.2)
  points(0, posterior[x==0], col=cols[2], pch=16, cex=1.2)
  
  legend("topleft", legend = c("prior", "posterior"), text.col=cols, bty="n")
  
  text(x = -2, y = .5*( max(c(prior, posterior))), labels=bquote(B["01"]~"="~.(round(posterior[x==0]/prior[x==0], 3))), adj=0)
}

plot_savdic()

```

## The Savage-Dickey Bayes factor

```{r, echo=F}
plot_savdic(prior_sd = 3)
```

## Summary

Steps we'll follow in our `brms` examples:

1. Figure out what model is appropriate for the data at hand
2. Specify reasonable priors for model parameters (need to be especially careful if you want Bayes factors)
3. Fit model (using `brms`, `Stan`, etc) and ensure chains have converged (we'll cover other possible problems/errors specific to `Stan`)
4. Posterior predictive plots - are there areas for improvement?
5. Refine model, compare competing models, ...
6. Examine posterior quantities (mean, median, CI, HDI)

## End of introduction to Bayesian analysis

Further reading:

- Kruschke (2015). [Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan.](https://www.sciencedirect.com/book/9780124058880/doing-bayesian-data-analysis) Chapter 7.
- Gelman et al. (2014). [Bayesian Data Analysis (3rd edition).](http://www.stat.columbia.edu/~gelman/book/) Chapters 6, 11 and 12.
- Kruschke, J. K., & Liddell, T. M. (2018). [The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective.](https://link.springer.com/article/10.3758/s13423-016-1221-4) Psychonomic Bulletin & Review, 25(1), 178-206.
